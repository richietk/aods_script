{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication of the paper's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. read the data\n",
    "# u.data -> userId, movieId, rating, timestamp\n",
    "# u.item -> movieId, title, releaseDate, videoReleaseDate, imdbURL, genre1..genre19 (binary)\n",
    "\n",
    "# read ratings\n",
    "rating_cols=[\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    "ratings=pd.read_csv(\n",
    "    \"data/u.data\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=rating_cols,\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "# read movies\n",
    "item_cols=[\n",
    "    \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"imdbURL\",\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\",\n",
    "    \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "    \"FilmNoir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\",\n",
    "    \"SciFi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "movies=pd.read_csv(\n",
    "    \"data/u.item\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=item_cols,\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "# 2. split data into train/test\n",
    "train_df, test_df=train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "\n",
    "# 3. build user x movie utility matrix from train\n",
    "all_user_ids=sorted(train_df[\"userId\"].unique())\n",
    "all_movie_ids=sorted(train_df[\"movieId\"].unique())\n",
    "\n",
    "user_to_index={u:i for i, u in enumerate(all_user_ids)}\n",
    "movie_to_index={m:i for i, m in enumerate(all_movie_ids)}\n",
    "\n",
    "# init utility matrix\n",
    "utility_matrix=np.zeros((len(all_user_ids), len(all_movie_ids)), dtype=np.float32)\n",
    "\n",
    "# fill known ratings\n",
    "for row in train_df.itertuples():\n",
    "    u_idx=user_to_index[row.userId]\n",
    "    m_idx=movie_to_index[row.movieId]\n",
    "    utility_matrix[u_idx, m_idx]=row.rating\n",
    "\n",
    "# 4. prepare features for k-means (19 genre columns)\n",
    "# subset of movies in training set\n",
    "movies_train=movies[movies[\"movieId\"].isin(all_movie_ids)].copy()\n",
    "\n",
    "# sort by movieId\n",
    "movies_train.sort_values(\"movieId\", inplace=True)\n",
    "movies_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# genre columns\n",
    "genre_cols=[\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\",\n",
    "    \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "    \"FilmNoir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\",\n",
    "    \"SciFi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "genre_features=movies_train[genre_cols].values # shape: (#movies_in_train, 19)\n",
    "\n",
    "# 5. choose number of clusters via wcss (optional \"elbow\")\n",
    "wcss=[]\n",
    "K_MAX=10\n",
    "for k in range(1, K_MAX+1):\n",
    "    km_temp=KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
    "    km_temp.fit(genre_features)\n",
    "    wcss.append(km_temp.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, K_MAX+1), wcss, marker='o')\n",
    "plt.title('K-Means Elbow on Movie Genres')\n",
    "plt.xlabel('k (#clusters)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# pick a cluster count\n",
    "\n",
    "def train_and_calculate(best_k):\n",
    "    # 6. cluster the movies using k-means\n",
    "    kmeans=KMeans(n_clusters=best_k, init='k-means++', random_state=42)\n",
    "    cluster_labels=kmeans.fit_predict(genre_features)\n",
    "\n",
    "    # map movieId -> cluster\n",
    "    movie_cluster_map=pd.DataFrame({\n",
    "        \"movieId\":movies_train[\"movieId\"],\n",
    "        \"cluster\":cluster_labels\n",
    "    })\n",
    "\n",
    "    # 7. build user x cluster matrix = avg rating per user per cluster\n",
    "    num_users=len(all_user_ids)\n",
    "    user_cluster_matrix=np.zeros((num_users, best_k), dtype=np.float32)\n",
    "    cluster_counts=np.zeros((num_users, best_k), dtype=np.float32)\n",
    "\n",
    "    # accumulate sums of ratings\n",
    "    for row in train_df.itertuples():\n",
    "        u_id=row.userId\n",
    "        m_id=row.movieId\n",
    "        rating=row.rating\n",
    "\n",
    "        # skip if not in training mapping\n",
    "        if m_id not in movie_to_index:\n",
    "            continue\n",
    "\n",
    "        u_idx=user_to_index[u_id]\n",
    "\n",
    "        # find movie's cluster\n",
    "        cluster_id_arr=movie_cluster_map.loc[movie_cluster_map[\"movieId\"]==m_id, \"cluster\"].values\n",
    "        if len(cluster_id_arr)==0:\n",
    "            continue\n",
    "        cluster_id=cluster_id_arr[0]\n",
    "\n",
    "        user_cluster_matrix[u_idx, cluster_id]+=rating\n",
    "        cluster_counts[u_idx, cluster_id]+=1\n",
    "\n",
    "    # convert sums to averages\n",
    "    for u_idx in range(num_users):\n",
    "        for c_idx in range(best_k):\n",
    "            if cluster_counts[u_idx, c_idx]>0:\n",
    "                user_cluster_matrix[u_idx, c_idx]/=cluster_counts[u_idx, c_idx]\n",
    "\n",
    "    # subtract user's mean rating if they rated > 1 cluster\n",
    "    user_cluster_matrix_normalized = np.copy(user_cluster_matrix)\n",
    "    for u_idx in range(num_users):\n",
    "        rated_cluster_count = np.sum(user_cluster_matrix[u_idx] > 0)\n",
    "        if rated_cluster_count > 1:\n",
    "            user_mean = np.nanmean(user_cluster_matrix[u_idx])\n",
    "            for c_idx in range(best_k):\n",
    "                if not np.isnan(user_cluster_matrix[u_idx, c_idx]):\n",
    "                    user_cluster_matrix_normalized[u_idx, c_idx] -= user_mean\n",
    "\n",
    "\n",
    "    # 8. user-user similarity via pearson correlation on user_cluster_matrix\n",
    "    corr=np.corrcoef(user_cluster_matrix)\n",
    "    corr=np.nan_to_num(corr) # replace NaNs with 0\n",
    "\n",
    "    # 9. prediction (knn)\n",
    "    def predict_rating(user_id, movie_id, topN=5, default_rating=3.0):\n",
    "        # predict rating for (user, movie)\n",
    "        if user_id not in user_to_index or movie_id not in movie_to_index:\n",
    "            return default_rating\n",
    "\n",
    "        u_idx=user_to_index[user_id]\n",
    "\n",
    "        # find cluster for movie\n",
    "        cluster_id_arr=movie_cluster_map.loc[movie_cluster_map[\"movieId\"]==movie_id, \"cluster\"].values\n",
    "        if len(cluster_id_arr)==0:\n",
    "            return default_rating\n",
    "        c_label=cluster_id_arr[0]\n",
    "\n",
    "        # get correlation with other users\n",
    "        user_sims=corr[u_idx, :]\n",
    "        # sort by similarity\n",
    "        neighbors_sorted=np.argsort(-user_sims)\n",
    "\n",
    "        sim_sum=0.0\n",
    "        weighted_sum=0.0\n",
    "        found_neighbors=0\n",
    "\n",
    "        for nbr_idx in neighbors_sorted:\n",
    "            if nbr_idx==u_idx:\n",
    "                continue\n",
    "\n",
    "            # neighbor's rating for cluster\n",
    "            nbr_rating=user_cluster_matrix[nbr_idx, c_label]\n",
    "\n",
    "            if nbr_rating>0:\n",
    "                sim=user_sims[nbr_idx]\n",
    "                weighted_sum+=sim*nbr_rating\n",
    "                sim_sum+=abs(sim)\n",
    "                found_neighbors+=1\n",
    "\n",
    "                if found_neighbors>=topN:\n",
    "                    break\n",
    "\n",
    "        if sim_sum==0:\n",
    "            return default_rating\n",
    "        return weighted_sum/sim_sum\n",
    "\n",
    "    # 10. evaluate on test set (rmse)\n",
    "    pred_ratings=[]\n",
    "    true_ratings=[]\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        user_id=row.userId\n",
    "        movie_id=row.movieId\n",
    "        actual=row.rating\n",
    "\n",
    "        pred=predict_rating(user_id, movie_id, topN=5)\n",
    "        pred_ratings.append(pred)\n",
    "        true_ratings.append(actual)\n",
    "\n",
    "    pred_ratings=np.array(pred_ratings)\n",
    "    true_ratings=np.array(true_ratings)\n",
    "\n",
    "    mse=np.mean((pred_ratings-true_ratings)**2)\n",
    "    rmse=sqrt(mse)\n",
    "    # evaluate on training set (rmse)\n",
    "    train_preds = []\n",
    "    train_truths = []\n",
    "\n",
    "    for row in train_df.itertuples():\n",
    "        user_id = row.userId\n",
    "        movie_id = row.movieId\n",
    "        actual = row.rating\n",
    "\n",
    "        pred = predict_rating(user_id, movie_id, topN=5)\n",
    "        train_preds.append(pred)\n",
    "        train_truths.append(actual)\n",
    "\n",
    "    train_preds = np.array(train_preds)\n",
    "    train_truths = np.array(train_truths)\n",
    "    train_mse = np.mean((train_preds - train_truths) ** 2)\n",
    "    train_rmse = sqrt(train_mse)\n",
    "\n",
    "    print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Test  RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below see our improved version of the paper's algorithm. We introduced a validation set to avoid the error of tuning the hyperparameters on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. read the data\n",
    "# u.data -> userId, movieId, rating, timestamp\n",
    "# u.item -> movieId, title, releaseDate, videoReleaseDate, imdbURL, genre1..genre19 (binary)\n",
    "\n",
    "# read ratings\n",
    "rating_cols=[\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    "ratings=pd.read_csv(\n",
    "    \"data/u.data\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=rating_cols,\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "# read movies\n",
    "item_cols=[\n",
    "    \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"imdbURL\",\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\",\n",
    "    \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "    \"FilmNoir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\",\n",
    "    \"SciFi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "movies=pd.read_csv(\n",
    "    \"data/u.item\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=item_cols,\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "# 2. split data into train/validation/test\n",
    "train_df, temp_df = train_test_split(ratings, test_size=0.3, random_state=42)  # 70% for training\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)  # 15% for validation, 15% for test\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# 3. build user x movie utility matrix from train\n",
    "all_user_ids = sorted(train_df[\"userId\"].unique())\n",
    "all_movie_ids = sorted(train_df[\"movieId\"].unique())\n",
    "\n",
    "user_to_index = {u: i for i, u in enumerate(all_user_ids)}\n",
    "movie_to_index = {m: i for i, m in enumerate(all_movie_ids)}\n",
    "\n",
    "# init utility matrix\n",
    "utility_matrix = np.zeros((len(all_user_ids), len(all_movie_ids)), dtype=np.float32)\n",
    "\n",
    "# fill known ratings\n",
    "for row in train_df.itertuples():\n",
    "    u_idx = user_to_index[row.userId]\n",
    "    m_idx = movie_to_index[row.movieId]\n",
    "    utility_matrix[u_idx, m_idx] = row.rating\n",
    "\n",
    "# 4. prepare features for k-means (19 genre columns)\n",
    "# subset of movies in training set\n",
    "movies_train = movies[movies[\"movieId\"].isin(all_movie_ids)].copy()\n",
    "\n",
    "# sort by movieId\n",
    "movies_train.sort_values(\"movieId\", inplace=True)\n",
    "movies_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# genre columns\n",
    "genre_cols = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\",\n",
    "    \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "    \"FilmNoir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\",\n",
    "    \"SciFi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "genre_features = movies_train[genre_cols].values  # shape: (#movies_in_train, 19)\n",
    "\n",
    "# 5. choose number of clusters via wcss (optional \"elbow\")\n",
    "wcss = []\n",
    "K_MAX = 10\n",
    "for k in range(1, K_MAX + 1):\n",
    "    km_temp = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
    "    km_temp.fit(genre_features)\n",
    "    wcss.append(km_temp.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, K_MAX + 1), wcss, marker='o')\n",
    "plt.title('K-Means Elbow on Movie Genres')\n",
    "plt.xlabel('k (#clusters)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# pick a cluster count (use validation set to decide)\n",
    "def choose_best_k():\n",
    "    best_rmse = float('inf')\n",
    "    best_k = 2  # Default initial best k\n",
    "\n",
    "    for k in range(2, 21):  # Try cluster counts from 2 to 20\n",
    "        rmse = train_and_calculate(k, val_df)\n",
    "        print(f\"RMSE for k={k}: {rmse:.4f}\")\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_k = k\n",
    "\n",
    "    print(f\"Best number of clusters: {best_k} with RMSE: {best_rmse:.4f}\")\n",
    "    return best_k\n",
    "\n",
    "# 6. train and calculate RMSE (based on validation data)\n",
    "def train_and_calculate(best_k, df_to_use):\n",
    "    # cluster the movies using k-means\n",
    "    kmeans = KMeans(n_clusters=best_k, init='k-means++', random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(genre_features)\n",
    "\n",
    "    # map movieId -> cluster\n",
    "    movie_cluster_map = pd.DataFrame({\n",
    "        \"movieId\": movies_train[\"movieId\"],\n",
    "        \"cluster\": cluster_labels\n",
    "    })\n",
    "\n",
    "    # build user x cluster matrix = avg rating per user per cluster\n",
    "    num_users = len(all_user_ids)\n",
    "    user_cluster_matrix = np.zeros((num_users, best_k), dtype=np.float32)\n",
    "    cluster_counts = np.zeros((num_users, best_k), dtype=np.float32)\n",
    "\n",
    "    # accumulate sums of ratings\n",
    "    for row in df_to_use.itertuples():\n",
    "        u_id = row.userId\n",
    "        m_id = row.movieId\n",
    "        rating = row.rating\n",
    "\n",
    "        # skip if not in training mapping\n",
    "        if m_id not in movie_to_index:\n",
    "            continue\n",
    "\n",
    "        u_idx = user_to_index[u_id]\n",
    "\n",
    "        # find movie's cluster\n",
    "        cluster_id_arr = movie_cluster_map.loc[movie_cluster_map[\"movieId\"] == m_id, \"cluster\"].values\n",
    "        if len(cluster_id_arr) == 0:\n",
    "            continue\n",
    "        cluster_id = cluster_id_arr[0]\n",
    "\n",
    "        user_cluster_matrix[u_idx, cluster_id] += rating\n",
    "        cluster_counts[u_idx, cluster_id] += 1\n",
    "\n",
    "    # convert sums to averages\n",
    "    for u_idx in range(num_users):\n",
    "        for c_idx in range(best_k):\n",
    "            if cluster_counts[u_idx, c_idx] > 0:\n",
    "                user_cluster_matrix[u_idx, c_idx] /= cluster_counts[u_idx, c_idx]\n",
    "\n",
    "    # subtract user's mean rating if they rated > 1 cluster\n",
    "    user_cluster_matrix_normalized = np.copy(user_cluster_matrix)\n",
    "    for u_idx in range(num_users):\n",
    "        rated_cluster_count = np.sum(user_cluster_matrix[u_idx] > 0)\n",
    "        if rated_cluster_count > 1:\n",
    "            user_mean = np.nanmean(user_cluster_matrix[u_idx])\n",
    "            for c_idx in range(best_k):\n",
    "                if not np.isnan(user_cluster_matrix[u_idx, c_idx]):\n",
    "                    user_cluster_matrix_normalized[u_idx, c_idx] -= user_mean\n",
    "\n",
    "    # user-user similarity via pearson correlation on user_cluster_matrix\n",
    "    corr = np.corrcoef(user_cluster_matrix)\n",
    "    corr = np.nan_to_num(corr)  # replace NaNs with 0\n",
    "\n",
    "    # prediction (knn)\n",
    "    def predict_rating(user_id, movie_id, topN=5, default_rating=3.0):\n",
    "        # predict rating for (user, movie)\n",
    "        if user_id not in user_to_index or movie_id not in movie_to_index:\n",
    "            return default_rating\n",
    "\n",
    "        u_idx = user_to_index[user_id]\n",
    "\n",
    "        # find cluster for movie\n",
    "        cluster_id_arr = movie_cluster_map.loc[movie_cluster_map[\"movieId\"] == movie_id, \"cluster\"].values\n",
    "        if len(cluster_id_arr) == 0:\n",
    "            return default_rating\n",
    "        c_label = cluster_id_arr[0]\n",
    "\n",
    "        # get correlation with other users\n",
    "        user_sims = corr[u_idx, :]\n",
    "        # sort by similarity\n",
    "        neighbors_sorted = np.argsort(-user_sims)\n",
    "\n",
    "        sim_sum = 0.0\n",
    "        weighted_sum = 0.0\n",
    "        found_neighbors = 0\n",
    "\n",
    "        for nbr_idx in neighbors_sorted:\n",
    "            if nbr_idx == u_idx:\n",
    "                continue\n",
    "\n",
    "            # neighbor's rating for cluster\n",
    "            nbr_rating = user_cluster_matrix[nbr_idx, c_label]\n",
    "\n",
    "            if nbr_rating > 0:\n",
    "                sim = user_sims[nbr_idx]\n",
    "                weighted_sum += sim * nbr_rating\n",
    "                sim_sum += abs(sim)\n",
    "                found_neighbors += 1\n",
    "\n",
    "                if found_neighbors >= topN:\n",
    "                    break\n",
    "\n",
    "        if sim_sum == 0:\n",
    "            return default_rating\n",
    "        return weighted_sum / sim_sum\n",
    "\n",
    "    # evaluate on test set (rmse)\n",
    "    pred_ratings = []\n",
    "    true_ratings = []\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        user_id = row.userId\n",
    "        movie_id = row.movieId\n",
    "        actual = row.rating\n",
    "\n",
    "        pred = predict_rating(user_id, movie_id, topN=5)\n",
    "        pred_ratings.append(pred)\n",
    "        true_ratings.append(actual)\n",
    "\n",
    "    pred_ratings = np.array(pred_ratings)\n",
    "    true_ratings = np.array(true_ratings)\n",
    "\n",
    "    mse = np.mean((pred_ratings - true_ratings) ** 2)\n",
    "    rmse = sqrt(mse)\n",
    "    train_preds = []\n",
    "    train_truths = []\n",
    "\n",
    "    for row in train_df.itertuples():\n",
    "        user_id = row.userId\n",
    "        movie_id = row.movieId\n",
    "        actual = row.rating\n",
    "\n",
    "        pred = predict_rating(user_id, movie_id, topN=5)\n",
    "        train_preds.append(pred)\n",
    "        train_truths.append(actual)\n",
    "\n",
    "    train_preds = np.array(train_preds)\n",
    "    train_truths = np.array(train_truths)\n",
    "    train_rmse = sqrt(np.mean((train_preds - train_truths) ** 2))\n",
    "\n",
    "    print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Validation/Test RMSE: {rmse:.4f}\")\n",
    "    return rmse\n",
    "\n",
    "# 7. choose best k based on validation set\n",
    "best_k = choose_best_k()\n",
    "\n",
    "# 8. final model evaluation on test set with best k\n",
    "print(f\"\\nFinal model with {best_k} clusters:\")\n",
    "train_and_calculate(best_k, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
